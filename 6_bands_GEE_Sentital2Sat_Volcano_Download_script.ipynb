{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "665380b9",
      "metadata": {
        "id": "665380b9"
      },
      "source": [
        "# Download representative images of volcanos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcfacdb8",
      "metadata": {
        "id": "dcfacdb8"
      },
      "source": [
        "Credit: this script derived from [Aaron Geller's blog post.](https://sites.northwestern.edu/researchcomputing/2021/11/19/downloading-satellite-images-made-easy/), including the use of functions based on his [EarthEngineToGeoTIFF repository.](https://github.com/ageller/EarthEngineToGeoTIFF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74c88e1d",
      "metadata": {
        "id": "74c88e1d"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "%pip install rasterio\n",
        "\n",
        "import rasterio\n",
        "from rasterio.plot import show as showRasterio\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from datetime import date\n",
        "from datetime import timedelta\n",
        "import zipfile\n",
        "import os\n",
        "import requests\n",
        "\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive  \n",
        "\n",
        "# drive roots\n",
        "DRIVE_MOUNT = '/content/drive'\n",
        "drive.mount(DRIVE_MOUNT, force_remount=True)\n",
        "\n",
        "# set up project directories\n",
        "PROJECT_DIR = DRIVE_MOUNT + \"/My Drive/Volcano_datasets/\"\n",
        "TMP_DIR = PROJECT_DIR + \"TempDIR/\"\n",
        "OUTPUT_IMAGE_DIR = PROJECT_DIR +\"Full_Sentinel_sat_10km/\"\n",
        "\n",
        "\n",
        "\n",
        "targets = pd.read_excel(PROJECT_DIR + \"Recent Eruptions.xlsx\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1iJapXtdlHe",
        "outputId": "12aebd66-1b6b-440d-c360-bf9eda27927b"
      },
      "id": "A1iJapXtdlHe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8396951f",
      "metadata": {
        "id": "8396951f"
      },
      "outputs": [],
      "source": [
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentinel 2 cloud mask removal from https://developers.google.com/earth-engine/tutorials/community/sentinel-2-s2cloudless\n",
        "\n",
        "# percent cloud filter allowable for sentinel2 images\n",
        "CLOUD_FILTER = 70\n",
        "CLD_PRB_THRESH = 20\n",
        "NIR_DRK_THRESH = 0.15\n",
        "CLD_PRJ_DIST = 1\n",
        "BUFFER = 50\n",
        "\n",
        "\n",
        "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
        "    # Import and filter S2 SR.\n",
        "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(start_date, end_date)\n",
        "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
        "\n",
        "    # Import and filter s2cloudless.\n",
        "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(start_date, end_date))\n",
        "\n",
        "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
        "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
        "        'primary': s2_sr_col,\n",
        "        'secondary': s2_cloudless_col,\n",
        "        'condition': ee.Filter.equals(**{\n",
        "            'leftField': 'system:index',\n",
        "            'rightField': 'system:index'\n",
        "        })\n",
        "    }))\n",
        "\n",
        "def add_cloud_bands(img):\n",
        "      # Get s2cloudless image, subset the probability band.\n",
        "      cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
        "\n",
        "      # Condition s2cloudless by the probability threshold value.\n",
        "      is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
        "\n",
        "      # Add the cloud probability layer and cloud mask as image bands.\n",
        "      return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
        "\n",
        "def add_shadow_bands(img):\n",
        "    # Identify water pixels from the SCL band.\n",
        "    not_water = img.select('SCL').neq(6)\n",
        "\n",
        "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
        "    SR_BAND_SCALE = 1e4\n",
        "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
        "\n",
        "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
        "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
        "\n",
        "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
        "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
        "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
        "        .select('distance')\n",
        "        .mask()\n",
        "        .rename('cloud_transform'))\n",
        "\n",
        "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
        "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
        "\n",
        "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
        "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
        "\n",
        "def add_cld_shdw_mask(img):\n",
        "    # Add cloud component bands.\n",
        "    img_cloud = add_cloud_bands(img)\n",
        "\n",
        "    # Add cloud shadow component bands.\n",
        "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
        "\n",
        "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
        "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
        "\n",
        "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
        "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
        "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
        "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
        "        .rename('cloudmask'))\n",
        "\n",
        "    # Add the final cloud-shadow mask to the image.\n",
        "    return img.addBands(is_cld_shdw)\n",
        "\n",
        "def apply_cld_shdw_mask(img):\n",
        "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
        "    not_cld_shdw = img.select('cloudmask').Not()\n",
        "\n",
        "    # Subset reflectance bands and update their masks, return the result.\n",
        "    return img.select('B.*').updateMask(not_cld_shdw)\n"
      ],
      "metadata": {
        "id": "BD5F5CMN_Tgs"
      },
      "id": "BD5F5CMN_Tgs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getBestImage(lon, lat, sze_km, rgb_filename, nir_filename,\n",
        "                         dateMin = '2020-04-01', dateMax = '2020-04-30', \n",
        "                         min = 0, vmax = 3500,\n",
        "                         temp_dir = TMP_DIR):\n",
        "    '''    \n",
        "    download an RGB image from the Sentinal S2 Surface Reflectance satellite, at the given coordinates\n",
        "    \n",
        "    lon : central longitude in degrees\n",
        "    lat : central latitude in degrees\n",
        "    sze_km : size of the edge of the box in km\n",
        "    dateMin : minimum date to use for image search in year-month-day (e.g., 2020-08-01)\n",
        "    dateMax : maximum date to use for image search in year-month-day (e.g., 2020-08-31)\n",
        "    vMin : minimum value to select in the Sentinal image pixels (I think this should be close to 0)\n",
        "    vMax : maximum value to select in the Sentinal image pixels (I think this should be close to 3000)\n",
        "    rgb_filename : output filename for the RGB GeoTIFF image\n",
        "    nir_filename : output filename for the RGB GeoTIFF image\n",
        "    \n",
        "    Note: it's possible that the vMin and vMax values should be different for each band to make the image look nicer\n",
        "    \n",
        "    https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR\n",
        "    '''\n",
        "\n",
        "\n",
        "    print('Downloading Sentinel S2 Surface Reflectance satellite images ... ')\n",
        "    \n",
        "    # define the area of interest, using the Earth Engines geometry object\n",
        "\n",
        "    pt = ee.Geometry.Point(lon,lat)\n",
        "    \n",
        "    aoi = ee.Geometry.buffer(pt,sze_km)\n",
        "\n",
        "    # get sentinal image remove clouds\n",
        "    col = get_s2_sr_cld_col(aoi, dateMin, dateMax)\\\n",
        "                            .map(add_cld_shdw_mask)\\\n",
        "                            .map(apply_cld_shdw_mask)\n",
        "\n",
        "    db = ee.Image(col.mosaic())\n",
        "\n",
        "    # add the latitude and longitude\n",
        "    db = db.addBands(ee.Image.pixelLonLat())\n",
        "\n",
        "\n",
        "    # define the bands that I want to use.  B4 is red, B3 is green, B2 is blue, b8 is near IR, \n",
        "    # https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR#bands\n",
        "    bands = ['B4', 'B3', 'B2','B5', 'B9', 'B8']\n",
        "\n",
        "    # export geotiff images, these go to Drive and then are downloaded locally\n",
        "    for selection in bands:\n",
        "        task = ee.batch.Export.image.toDrive(image=db.select(selection),\n",
        "                                     description=selection,\n",
        "                                     scale=30,\n",
        "                                     region=aoi,\n",
        "                                     fileNamePrefix=selection,\n",
        "                                     crs='EPSG:4326',\n",
        "                                     fileFormat='GeoTIFF')\n",
        "        task.start()\n",
        "\n",
        "        url = db.select(selection).getDownloadURL({\n",
        "            'scale': 30,\n",
        "            'crs': 'EPSG:4326',\n",
        "            'fileFormat': 'GeoTIFF',\n",
        "            'region': aoi})\n",
        "    \n",
        "        r = requests.get(url, stream=True)\n",
        "\n",
        "        filenameZip = temp_dir + selection+'.zip'\n",
        "        filenameTif = selection+'.tif'\n",
        "\n",
        "        # unzip and write the tif file, then remove the original zip file\n",
        "        with open(filenameZip, \"wb\") as fd:\n",
        "            for chunk in r.iter_content(chunk_size=1024):\n",
        "                fd.write(chunk)\n",
        "\n",
        "        zipdata = zipfile.ZipFile(filenameZip)\n",
        "        zipinfos = zipdata.infolist()\n",
        "\n",
        "        # iterate through each file (there should be only one)\n",
        "        for zipinfo in zipinfos:\n",
        "            zipinfo.filename = filenameTif\n",
        "            zipdata.extract(zipinfo,path=temp_dir)\n",
        "    \n",
        "        zipdata.close()\n",
        "        \n",
        "    # create a combined RGB geotiff image\n",
        "    # https://gis.stackexchange.com/questions/341809/merging-sentinel-2-rgb-bands-with-rasterio\n",
        "    print('Creating RGB image ... ')\n",
        "    B2 = rasterio.open(temp_dir +'B2.tif')\n",
        "    B3 = rasterio.open(temp_dir +'B3.tif')\n",
        "    B4 = rasterio.open(temp_dir +'B4.tif')\n",
        "\n",
        "    # get the scaling\n",
        "    image = np.array([B2.read(1), B3.read(1), B4.read(1)]).transpose(1,2,0)\n",
        "    p2, p98 = np.percentile(image, (2,98))\n",
        "\n",
        "    # use the B3 image as a starting point so that I keep the same parameters\n",
        "    B3_geo = B3.profile\n",
        "    B3_geo.update({'count': 3})\n",
        "\n",
        "    with rasterio.open(rgb_filename, 'w', **B3_geo) as dest:\n",
        "        dest.write( (np.clip(B4.read(1), p2, p98) - p2)/(p98 - p2)*255, 1)\n",
        "        dest.write( (np.clip(B3.read(1), p2, p98) - p2)/(p98 - p2)*255, 2)\n",
        "        dest.write( (np.clip(B2.read(1), p2, p98) - p2)/(p98 - p2)*255, 3)\n",
        "\n",
        "\n",
        "    dest.close()\n",
        "\n",
        "    print('Creating NIR image ... ')\n",
        "    # open the images\n",
        "    B5 = rasterio.open(temp_dir +'B5.tif')\n",
        "    B8 = rasterio.open(temp_dir +'B8.tif')\n",
        "    B9 = rasterio.open(temp_dir +'B9.tif')\n",
        "\n",
        "    # get the scaling\n",
        "    image = np.array([B5.read(1), B8.read(1), B9.read(1)]).transpose(1,2,0)\n",
        "    p2, p98 = np.percentile(image, (2,98))\n",
        "\n",
        "    with rasterio.open(nir_filename, 'w', **B3_geo) as dest:\n",
        "        dest.write( (np.clip(B5.read(1), p2, p98) - p2)/(p98 - p2)*255, 1)\n",
        "        dest.write( (np.clip(B8.read(1), p2, p98) - p2)/(p98 - p2)*255, 2)\n",
        "        dest.write( (np.clip(B9.read(1), p2, p98) - p2)/(p98 - p2)*255, 3)\n",
        "\n",
        "\n",
        "    dest.close()\n",
        "    \n",
        "    B5.close()\n",
        "    B8.close()\n",
        "    B9.close()\n",
        "    \n",
        "    # remove the intermediate files\n",
        "    for selection in bands:\n",
        "        os.remove(temp_dir +selection + '.tif')\n",
        "        os.remove(temp_dir +selection + '.zip')\n",
        "  \n"
      ],
      "metadata": {
        "id": "y9pcFV1wSsZ3"
      },
      "id": "y9pcFV1wSsZ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_data(longitude, latitude, buffer_size,\n",
        "                             output_rgb,output_grn, \n",
        "                            dateMin , dateMax ):\n",
        "   # download stacked tif files\n",
        "    _ = getBestImage(longitude, latitude, buffer_size,\n",
        "                             output_rgb+\".tif\",output_grn+\".tif\", \n",
        "                            dateMin , dateMax )\n",
        "\n",
        "    #convert from tif to png\n",
        "    for file in [output_rgb,output_grn]:\n",
        "        f,ax = plt.subplots(figsize=(15,15))\n",
        "\n",
        "        img = rasterio.open(file+\".tif\")\n",
        "\n",
        "        showRasterio(img.read(), ax = ax, transform=img.transform)\n",
        "\n",
        "        f.savefig(file+\".png\", bbox_inches='tight')\n",
        "\n",
        "        img.close()\n",
        "\n",
        "        plt.close(f)\n",
        "        os.remove(file + \".tif\")\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "JP5prJJ5p7kh"
      },
      "id": "JP5prJJ5p7kh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_size_km = 10000\n",
        "for i_eruption in range(84,targets.shape[0]):\n",
        "    volc = targets.loc[i_eruption]\n",
        "    v_name = re.sub(r\"[,.]\",\"\",re.sub(r\"\\s+\", \"_\",volc[\"Volcano Name\"]))\n",
        "   \n",
        "\n",
        "    # adjust eruption date by 1 year\n",
        "    erupt_start_date = date(volc[\"Start Year\"].astype(int),\n",
        "                            volc[\"Start Month\"].astype(int),\n",
        "                            volc[\"Start Day\"].astype(int))\n",
        "    erupt_end_date = date(volc[\"End Year\"].astype(int),\n",
        "                          volc[\"End Month\"].astype(int),\n",
        "                          volc[\"End Day\"].astype(int))\n",
        "\n",
        "    if (erupt_start_date >= date(2015,6,23)):\n",
        "      print(v_name,erupt_start_date)\n",
        "    # do prior to eruption too\n",
        "      pre_erupt_date = erupt_start_date - timedelta(weeks=1)\n",
        "\n",
        "      volc_file_name = f'{OUTPUT_IMAGE_DIR}{v_name}__{pre_erupt_date}_pre_{volc[\"Volcano Number\"]:.0f}_{volc[\"Eruption Number\"]:.0f}'\n",
        "      print(i_eruption, volc_file_name)\n",
        "        \n",
        "      try:\n",
        "          get_image_data(volc[\"Longitude\"], volc[\"Latitude\"], target_size_km,\n",
        "                              volc_file_name,volc_file_name+\"_b5_b8_b9\", \n",
        "                              dateMin = pre_erupt_date.isoformat(), dateMax=erupt_start_date.isoformat())\n",
        "      except Exception as e:\n",
        "          print(f'Failed to get data for {volc_file_name}')\n",
        "          print(e)\n",
        "      \n",
        "      next_start_date = erupt_start_date\n",
        "      next_end_date = erupt_start_date + timedelta(days=7)\n",
        "      while (next_end_date <= erupt_end_date + timedelta(days=7) and next_end_date <= erupt_start_date + timedelta(days=187)):\n",
        "          volc_file_name = f'{OUTPUT_IMAGE_DIR}{v_name}_{next_start_date}_{volc[\"Volcano Number\"]:.0f}_{volc[\"Eruption Number\"]:.0f}'\n",
        "\n",
        "          print(i_eruption, volc_file_name)\n",
        "          try:\n",
        "              get_image_data(volc[\"Longitude\"], volc[\"Latitude\"], target_size_km,\n",
        "                              volc_file_name,volc_file_name+\"_b5_b8_b9\", \n",
        "                              dateMin = next_start_date.isoformat(), dateMax=next_end_date.isoformat())\n",
        "          except Exception as e:\n",
        "            print(f'Failed to get data for {volc_file_name}:\\n {e}')\n",
        "          next_start_date = next_start_date + timedelta(days=7)\n",
        "          next_end_date = next_end_date + timedelta(days=7)\n",
        "        "
      ],
      "metadata": {
        "id": "V3-iEGY8hezd"
      },
      "id": "V3-iEGY8hezd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "6 bands GEE Sentital2Sat Volcano Download script",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}